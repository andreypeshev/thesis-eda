---
title: "Bachelor's Thesis: Simulation Data EDA"
author: "Andrey Peshev"
output: html_notebook
---
* PRB = Percentage Relative Bias  
* MCSD = Monte Carlo Standard Deviation\
* Data generation equation: Y = 1.0 + 0.33X + 0.33Z1 + 0.33Z2 + e\

Simulation parameters: \
Proportion of the MAR predictor represented in the analysis model: pMAR = {1.0, 0.75, 0.5, 0.25, 0.0}\
Strength of correlations among the predictors: rXZ = {0.0, 0.1, 0.3, 0.5}\
Sample size: N = {100, 250, 500}\
Proportion of missing data: PM = {0.1, 0.2, 0.4}\
R^2^ for the data generating model: R^2 = {0.15, 0.3, 0.6}\
number of imputations:\ 
imputation type: MID, MI, CC 


## Importing data and libraries
```{r Imports}
#clear the working environment 
rm(list=ls())

#import libraries
library(ggplot2)
library(dplyr)
#install.packages("cowplot")
library(cowplot)
#install.packages("xtable")
library(xtable)


#import data
all_data <- readRDS("masked_outcome_measures.rds")
data_prb <- all_data$prb
data_mcsd <- all_data$mcsd
```

## 1. Understanding the structure of the data 
+ #### Data summaries\

```{r}
#general summary of the data
summary(data_prb)
summary(data_mcsd)
```
Columns **a** through **g** are the different conditions of the simulation. An interesting thing to note is that condition **1** of parameter **a** has only 540 occurrences and condition **8** of parameter **b** has 1620.\

+ #### Number of unique conditions for each parameter:\
```{r}
str(data_prb)
```
The analysis will begin with the PRB because it is necessary to understand which conditions are biased in order to make cross-references with the MCSD.

+ #### Boxplots with condition on the x-axis and PRB on y-axis for int, x, z1:\
```{r}
#boxplots for prb with the different conditions for x
for (i in 1:length(data_prb[1:7])){
  print(ggplot(data_prb, aes(x=data_prb[, i], y=x)) + geom_boxplot() + xlab(colnames(data_prb[i])))
}
```

```{r min and max values}
# min and max PRB for x
data_prb[which.min(abs(data_prb$x)),]
data_prb[which.max(abs(data_prb$x)),]

# min and max MCSD for x
data_mcsd[which.min(abs(data_mcsd$x)),]
data_mcsd[which.max(abs(data_mcsd$x)),]

```

```{r}
xtabs(~ a+b, data=data_prb)
```
Condition 1 for the a parameter is only paired with condition 8 of the b parameter.

For-loop comparing conditions of col f and col g

```{r}
#euclidean distance formula 
euclideanDistance <- function(x) sqrt(sum((x - mean(x))^2))
```

Creating a function that calculates the euclidean distance between all conditions in a column. After that it orders the data by euclidean distance descending.  

```{r}
CalcEucDist <- function(data, col){
  
  #create a grid with all possible combinations 
  exp_data <- expand.grid(sapply(data[, -which(names(data) %in% c(col, "int", "x", "z1"))], levels))

  #empty vector for saving Euc. distances
  euc_vec <- rep(0, nrow(exp_data))

  #looping through all possible conditions
  for (n in 1:nrow(exp_data)){
  
    #filtering the data based on current set of conditions
    cols_exp <- colnames(exp_data)
  
    filt_data <- data %>% filter(data[, cols_exp[1]] == exp_data[n, 1], 
                                 data[, cols_exp[2]] == exp_data[n, 2], 
                                 data[, cols_exp[3]] == exp_data[n, 3], 
                                 data[, cols_exp[4]] == exp_data[n, 4], 
                                 data[, cols_exp[5]] == exp_data[n, 5], 
                                 data[, cols_exp[6]] == exp_data[n, 6])
  
  
    #calculating Euclidean distance
    euc_vec[n] <- euclideanDistance(filt_data$x)
    
    #saving the data
    comb_data <- cbind(exp_data, euc_vec)
    out_data <- comb_data[comb_data$euc_vec != 0, ]
    out_data <- out_data[order(-out_data$euc_vec), ]
  }
  
  out_data
  
}

```

```{r}

start.time <- Sys.time()

params <- colnames(data_prb[1:7])

for(param in params){
  assign(paste0("data_", param), CalcEucDist(data_prb, param))
}

end.time <- Sys.time()
end.time - start.time

```

Seeing which conditions appear the most in the top 1000 rows with the largest euclidean distance for each parameter. 

``` {r}

data_vec <- list(data_a, data_b, data_c, data_d, data_e, data_f, data_g)
for (data in data_vec){
  #list_plots <- list()
  #for(col in 1:6){
  #  list_plots[[col]] <- ggplot(data[1:1000, ], aes(x=data[1:1000, col]), y=stat(count)) + geom_bar() +xlab(colnames(data[col]))
    
  #}
  print(summary(data[1:1000, ]))
  #print(plot_grid(plotlist=list_plots))
  #print(list_plots)
}


```

```{r}
plots_a <- list()

for(i in 1:6){
  plot <- ggplot(data_a[1:1000, ], aes_string(x=names(data_a)[i]))
  plots_a[[i]] <-  plot + geom_bar(y=stat(count))
} 

```
Possible problem conditions are c == 3, e == 1, a == 3 and a == 2. They seem to produce large PRB combined with all other parameters. When comparing conditions in parameter a, d == 1 and d == 2 seem to have the largest frequnecy. The same could be said about conditions g == 3 and g == 4, as well.  

Visualizing data_prb with the suspected problematic conditions. 


```{r}

for(col in 1:7){
  if (col == 1){
    large_prb <- data_prb %>% filter(c==3) 
    print(ggplot(large_prb, aes(x=large_prb[, col], y=x)) 
          + geom_boxplot()   
          + xlab(colnames(data_prb[col])))
  
  }else if(col == 3){
    large_prb <- data_prb %>% filter(e==1) 
    print(ggplot(large_prb, aes(x=large_prb[, col], y=x)) 
          + geom_boxplot() 
          + xlab(colnames(data_prb[col])))
  
  }else if(col == 5){
     large_prb <- data_prb %>% filter(c==3)
     print(ggplot(large_prb, aes(x=large_prb[, col], y=x)) 
          + geom_boxplot() 
          + xlab(colnames(data_prb[col])))
     
  }else{
     large_prb <- data_prb %>% filter(e==3)
     print(ggplot(large_prb, aes(x=large_prb[, col], y=x)) 
          + geom_boxplot()  
          + xlab(colnames(data_prb[col])))
  }
 

}

```

``` {r}

data_vec <- list(data_a, data_b, data_c, data_d, data_e, data_f, data_g)

for (data in data_vec){
  print(summary(data[1:1000, ]))
}

```



```{r}

plot_a <- data_prb %>% 
  filter(c==3 & e==1) %>%
  ggplot(aes(x=a, y=x)) + geom_boxplot() + theme_classic()
 
plot_b <- data_prb %>% 
  filter(a==3 & c==3 & e==1) %>%
  ggplot(aes(x=b, y=x)) + geom_boxplot() + theme_classic() 
    
 
plot_c <- data_prb %>% 
  filter(a==3 & e==1) %>%
  ggplot(aes(x=c, y=x)) + geom_boxplot() + theme_classic()
    
  
plot_d <- data_prb %>% 
  filter(a==3 & c==3 & e==1) %>%
  ggplot(aes(x=d, y=x)) + geom_boxplot() + theme_classic()
          

plot_e <- data_prb %>% 
  filter(a==3 & c==3) %>%
  ggplot(aes(x=e, y=x)) + geom_boxplot() + theme_classic()

 
plot_f <- data_prb %>% 
  filter(a==3 & c==3 & e==1) %>%
  ggplot(aes(x=f, y=x)) + geom_boxplot() + theme_classic()
          
     
plot_g <- data_prb %>% 
  filter(a==3 & c==3 & e==1) %>% 
  ggplot(aes(x=g, y=x)) + geom_boxplot() + theme_classic()
          
plot_grid(plot_a, plot_b, plot_c, plot_d, plot_e, plot_f, plot_g)
```

```{r}

plot_a <- data_prb %>% 
  filter(c==3 & e==1) %>%
  ggplot(aes(x=a, y=x)) + geom_boxplot() + theme_classic()
 
plot_b <- data_prb %>% 
  filter(a==2 & c==3 & e==1) %>%
  ggplot(aes(x=b, y=x)) + geom_boxplot() + theme_classic()
    
 
plot_c <- data_prb %>% 
  filter(a==2 & e==1) %>%
  ggplot(aes(x=c, y=x)) + geom_boxplot() + theme_classic()
    
  
plot_d <- data_prb %>% 
  filter(a==2 & c==3 & e==1) %>%
  ggplot(aes(x=d, y=x)) + geom_boxplot() + theme_classic()
          

plot_e <- data_prb %>% 
  filter(a==2 & c==3) %>%
  ggplot(aes(x=e, y=x)) + geom_boxplot() + theme_classic()

 
plot_f <- data_prb %>% 
  filter(a==2 & c==3 & e==1) %>%
  ggplot(aes(x=f, y=x)) + geom_boxplot() + theme_classic()
          
     
plot_g <- data_prb %>% 
  filter(a==2 & c==3 & e==1) %>% 
  ggplot(aes(x=g, y=x)) + geom_boxplot() + theme_classic()
          
plot_grid(plot_a, plot_b, plot_c, plot_d, plot_e, plot_f, plot_g)
#ggsave("aec_filtered_boxplots2.png")
```

```{r}

#running the Euclidean distance for all parameters 
start.time <- Sys.time()

params <- colnames(data_mcsd[1:7])

for(param in params){
  assign(paste0("data_mcsd_", param), CalcEucDist(data_prb, param))
}

end.time <- Sys.time()
end.time - start.time

```

```{r}

for(col in 1:7){
  if (col == 1){
    large_mcsd <- data_mcsd %>% filter(c==3 & e==1) 
    print(ggplot(large_mcsd, aes(x=large_mcsd[, col], y=x)) 
          + geom_boxplot()  
          + xlab(colnames(data_mcsd[col])))
  
  }else if(col == 3){
    large_mcsd <- data_mcsd %>% filter(a==3 & e==1) 
    print(ggplot(large_mcsd, aes(x=large_mcsd[, col], y=x)) 
          + geom_boxplot()   
          + xlab(colnames(data_mcsd[col])))
  
  }else if(col == 5){
     large_mcsd <- data_mcsd %>% filter(a==3 & c==3) 
     print(ggplot(large_mcsd, aes(x=large_mcsd[, col], y=x)) 
          + geom_boxplot() 
          + xlab(colnames(data_mcsd[col])))
     
  }else{
     large_mcsd <- data_mcsd %>% filter(a==3 & c==3 & e==1)
     print(ggplot(large_mcsd, aes(x=large_mcsd[, col], y=x)) 
          + geom_boxplot()  
          + xlab(colnames(data_mcsd[col])))
  }
}

```

MCSD for the same combination of parameters seems to be spread out.

``` {r}

data_vec <- list(data_mcsd_a, data_mcsd_b, data_mcsd_c, data_mcsd_d, data_mcsd_e, data_mcsd_f, data_mcsd_g)

for (data in data_vec){
  print(summary(data[1:1000, ]))
}

```

Mean PRB with all possible combinations of parameters a, c and e. 
```{r}
combinations_ace <- expand.grid(lapply(data_prb[, c("a", "c", "e")], levels))
mean_prb<- rep(0, nrow(combinations_ace))

for(row in 1:nrow(combinations_ace)){
  filtered_data <- data_prb %>%
    filter(a==combinations_ace[row,1],
           c==combinations_ace[row,2],
           e==combinations_ace[row,3])
  
  mean_prb[row] <- mean(filtered_data$x)
  }

mean_data_ace <- cbind(combinations_ace, mean_prb)
mean_data_ace <- mean_data_ace[order(mean_data_ace$mean_prb), ]
mean_data_ace
#print(xtable(mean_data_ace), include.rownames=FALSE)
```

Mean PRB with all possible combinations of parameters d and f. 
```{r}
combinations_fd <- expand.grid(lapply(data_prb[, c("d", "f")], levels))
mean_prb<- rep(0, nrow(combinations_fd))

for(row in 1:nrow(combinations_fd)){
  filtered_data <- data_prb %>% filter(d==combinations_fd[row,1],
                                       f==combinations_fd[row,2])
                                       
  mean_prb[row] <- mean(filtered_data$x)
  }

mean_data_fd <- cbind(combinations_fd, mean_prb)
mean_data_fd <- mean_data_fd[order(mean_data_fd$mean_prb), ]
mean_data_fd
```

MCSD with all possible combinations of e, c, g and g.
```{r}
combinations_cefg <- expand.grid(lapply(data_mcsd[, c("c", "e", "f","g")], levels))
mean_mcsd <- rep(0, nrow(combinations_cefg))

for(row in 1:nrow(combinations_cefg)){
  filtered_data <- data_mcsd %>%
    filter(c==combinations_cefg[row,1],
           e==combinations_cefg[row,2],
           f==combinations_cefg[row,3],
           g==combinations_cefg[row,4])
  
  
  mean_mcsd[row] <- mean(filtered_data$x)
 }

mean_mcsd_cefg <- cbind(combinations_cefg, mean_mcsd)
mean_mcsd_cefg <- mean_mcsd_cefg[order(-mean_mcsd_cefg$mean_mcsd), ]
mean_mcsd_cefg
#print(xtable(mean_mcsd_cefg), include.rownames=FALSE)
```

Boxplots for all conditions filtered on c==3 & e==1 & f==1 & g==4.
```{r}

plot_a <- data_mcsd %>% 
  filter(c==3 & e==1 & f==1 & g==4) %>%
  ggplot(aes(x=a, y=x)) + geom_boxplot() + theme_classic()
 
plot_b <- data_mcsd %>% 
  filter(c==3 & e==1 & f==1 & g==4) %>%
  ggplot(aes(x=b, y=x)) + geom_boxplot() + theme_classic()
    
 
plot_c <- data_mcsd %>% 
  filter(e==1 & f==1 & g==4) %>%
  ggplot(aes(x=c, y=x)) + geom_boxplot() + theme_classic()
    
  
plot_d <- data_mcsd %>% 
  filter(c==3 & e==1 & f==1 & g==4) %>%
  ggplot(aes(x=d, y=x)) + geom_boxplot() + theme_classic()
          
  
plot_e <- data_mcsd %>% 
  filter(c==3 & f==1 & g==4) %>%
  ggplot(aes(x=e, y=x)) + geom_boxplot() + theme_classic()
          
 
plot_f <- data_mcsd %>% 
  filter(c==3 & e==1 & g==4) %>%
  ggplot(aes(x=f, y=x)) + geom_boxplot() + theme_classic()
          
     
plot_g <- data_mcsd %>% 
  filter(c==3 & e==1 & f==1) %>% 
  ggplot(aes(x=g, y=x)) + geom_boxplot() + theme_classic()
          
plot_grid(plot_a, plot_b, plot_c, plot_d, plot_e, plot_f, plot_g)
```